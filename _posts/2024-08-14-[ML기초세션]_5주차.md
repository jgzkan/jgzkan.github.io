---
layout: post
title: "[ML기초세션]_5주차"
published: true
date: 2024-08-14
math: true
categories: 
tags: KHUDA ML
---


# 세션 전 학습 내용 #

교재: p.220 ~ p.283

## [5-1] 결정 트리 ##

>**핵심 키워드: 결정 트리, 불순도, 정보 이득, 가지치기, 특성 중요도**

#### 로지스틱 회귀 모델로의 와인 분류 문제 접근 ####

```python
import pandas as pd

wine = pd.read_csv('https://bit.ly/wine_csv_data')

wine.head()
```
!['img1'](assets/img/ML_week5/img1.png)

- info(): df의 각 열의 데이터 타입과 누락된 데이터가 있는지 확인하는데 유용
!['img2'](assets/img/ML_week5/img2.png)

> 만약 누락된 값이 있다면 그 데이터를 버리거나, 평균값을 채우는 등 전처리 과정이 필요

- describe(): 열에 대한 간략한 통계를 출력

!['img3'](assets/img/ML_week5/img3.png)

특성들의 스케일이 다르기에, 표준화 필요

```python
data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()


from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    data, target, test_size=0.2, random_state=42)


from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(train_input)

train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)
```

표준 점수로 변환된 train_scaled와 test_scaled를 사용해 로지스틱 회귀 모델 훈련

```python
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(train_scaled, train_target)

print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))

#점수가 낮으므로 언더피팅 예상


#coef, intercept 출력
print(lr.coef_, lr.intercept_)
```

우리는 이 모델이 왜 저런 계수 값을 학습했는지 정확히 이해할 수 없다. 
대부분의 ML 모델은 이렇게 학습의 결과를 설명하기 어렵다. 


#### 결정 트리 ####

**결정 트리 모델은 이유를 설명하기 쉽다.**

> DT에서 random_state는 굳이 필요하지 않다. 예제에서는 설명을 위해 추가함

```python
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
dt.fit(train_scaled, train_target)

print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))

#오버피팅된 결과 출력
```

- plot_tree(): DT를 이해하기 쉬운 트리 그림으로 출력하는 사이킷런의 함수

```python
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(10,7))
plot_tree(dt)
plt.show()
```
!['img4'](assets/img/ML_week5/img4.png)


- max_depth 매개변수: 트리의 최대 깊이 제한
- filled 매개변수: 클래스에 맞게 노드 색칠하기
- feature_names 매개변수: 특성 이름 전달

```python
plt.figure(figsize=(10,7))
plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```
!['img5'](assets/img/ML_week5/img5.png)


**불순도**

- 지니 불순도(gini impurity): DecisionTreeClassifier 클래스의 criterion 매개변수 기본값
!['img6'](assets/img/ML_week5/img6.png)

- 정보 이득(information gain): 부모 노드와 자식 노드 사이의 불순도 차이

- 엔트로피 불순도: criterion = 'entropy' 지정하여 사용가능. 밑이 2인 로그를 사용하여 곱한다. 

!['img7'](assets/img/ML_week5/img7.png)


> 결정트리 알고리즘은 불순도 기준을 사용해 정보 이득이 최대가 되도록 노드를 분할한다. 노드를 순수하게 나눌수록 정보 이득이 커진다. 새로운 샘플에 대해 예측할 때는 마지막에 도달한 노드의 클래스 비율을 보고 예측한다. 


**가지치기**

- max_depth 지정 가지치기

```python
dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_input, train_target)

print(dt.score(train_input, train_target))
print(dt.score(test_input, test_target))
# 0.845 / 0.842

plt.figure(figsize=(20,15))
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```
!['img8'](assets/img/ML_week5/img8.png)

- DT의 장점: 특성값의 스케일이 계산에 영향을 미치지 않기 때문에 표준화 전처리 과정이 필요 없다.

- feature_importances_ 속성: 특성 중요도 저장, 각 노드의 정보 이득과 전체 샘플에 대한 비율을 곱한 후 특성별로 더하여 계산한다. 특성 중요도를 활용하여 DT의 특성 선택에 활용할 수 있다!

```python
print(dt.feature_importances_)

# [0.12345626(alchohol) 0.86862934(sugar) 0.0079144(pH) ]
```

결정 트리는 비전문가에게도 설명하기 쉬운 모델을 만든다. 
뿐만 아니라 결정 트리는 많은 앙상블 학습 알고리즘의 기반이 된다. 
앙상블 학습은 신경망과 함께 가장 높은 성능을 내기에 인기가 높은 알고리즘이다.

### 핵심 패키지와 함수 ###

> pandas
- info(): df의 요약 정보 출력. index, column type, null이 아닌 값의 개수, 메모리 사용량 제공. verbose 매개변수를 False로 바꾸면 각 열에 대한 정보는 출력하지 않는다.
- describe(): df 열의 통계 값을 제공한다. 수치형일 경우 min, max, avg, std, 사분위값 등이 출력. 문자열 같은 객체 타입의 열은 가장 자주 등장한 값과 횟수 출력. percentiles 매개변수에서는 백분위수를 지정한다. 

> scikit-learn
- **DecisionTreeClassifier**: 결정 트리 분류 클래스
- cirterion 매개변수: 불순도를 지정하며, 기본값은 지니 불순도이고 엔트로피 불순도를 사용할 수 있다.
- splitter 매개변수: 노드 분할 전략 선택. 기본값은 'best'로 정보 이득이 최대가 되도록 분할한다. 'random'이면 임의로 노드를 분할한다. 
- max_depth: 트리가 성장할 최대 깊이를 지정한다. 기본값은 None으로 리프노드가 순수하거나  min_samples_split보다 샘플 개수가 적을 때까지 성장한다.
- min_samples_split: 노드를 나누기 위한 최소 샘플 개수다. 기본값은 2.
- max_features 매개변수: 최적의 분할을 위해 탐색할 특성의 개수를 지정. 기본값은 None으로 모든 특성 사용. 
- **plot_tree()**: DT모델 시각화. 첫 번째 매개변수로 결정 트리 모델 객체를 전달한다. 
- max_depth 매개변수: 나타낼 트리 깊이 지정. 기본값은 None.
- feature_names 매개변수: 특성의 이름 지정
- filled 매개변수: 타깃값에 따라 노드 안에 색을 채운다.


## [5-2] 교차 검증과 그리드 서치 ##

>**핵심 키워드: 검증 세트, 교차 검증, 그리드 서치, 랜덤 서치**


지금까지 우리는 훈련 세트에서 모델을 훈련하고 테스트 세트에서 모델을 평가했다. 그런데 테스트 세트를 사용해 자꾸 성능을 확인하다 보면 점점 테스트 세트에 맞추게 되는 셈이다. 
테스트 세트로 일반화 성능을 올바르게 예측하려면 가능한 한 테스트 세트를 사용하지 말아야 한다. 모델을 만들고 나서 마지막 딱 한 번만 사용하는 것이 좋다. 


#### 검증 세트 ####

테스트 세트를 사용하지 않고 모델이 과대적합인지 과소적합인지 판단하는 가장 간단한 방법은 훈련 세트를 또 나누어 검증세트를 만드는 것이다. 

!['img9'](assets/img/ML_week5/img9.png)

> 보통은 20~30%를 테스트 세트와 훈련 세트로 떼어 놓지만 훈련 데이터가 아주 많다면 단 몇 %만 떼어 놓아도 전체 데이터를 대표하는 데 문제가 없다. 

1. 훈련 세트에서 모델을 훈련하고 검증 세트로 모델을 평가한다. 이런 식으로 테스트 하고 싶은 매개변수를 바꿔가며 가장 좋은 모델을 고른다. 
2. 그다음 이 매개변수를 사용해 훈련 세트와 검증 세트를 합쳐 전체 훈련 데이터에서 모델을 다시 훈련한다. 
3. 마지막에 테스트 세트에서 최종 점수를 평가한다. 

```python
import pandas as pd

wine = pd.read_csv('https://bit.ly/wine_csv_data')

data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()


from sklearn.model_selection import train_test_split

# training set, test set spliting
train_input, test_input, train_target, test_target = train_test_split(
    data, target, test_size=0.2, random_state=42)

# training set에서 validation set 만들기. test_size도 20% 재설정
sub_input, val_input, sub_target, val_target = train_test_split(
    train_input, train_target, test_size=0.2, random_state=42)

```


#### 교차 검증 ####

1. 검증세트를 떼어 내어 평가하는 과정을 여러 번 반복한다. 
2. 그 다음 이 점수를 평균하여 최종 검증 점수를 얻는다.

- 3-폴드 교차 검증
!['img10'](assets/img/ML_week5/img10.png)


> k-폴드 교차 검증(k-fold cross validation): 훈련 세트를 k개로 나누어 교차 검증을 수행하는 것

보통 5-폴드 교차 검증이나 10-폴드 교차 검증을 많이 사용한다.
이렇게 하면 데이터의 80-90%까지 훈련에 사용할 수 있다. 
검증 세트가 줄어들지만 각 폴드에서 계산한 검증 점수를 평균하기 때문에 안정된 점수로 생각할 수 있다. 

- cross_validate() 함수: 평가할 모델 객체를 첫 번째 매개변수로 전달하고, 그다음 검증 세트를 떼어 내지 않은 훈련 세트 전체를 함수에 전달한다. 

> cross_val_scrore() 함수: cross_validate() 함수의 결과 중에서 test_score 값만 반환한다. 

```python
from sklearn.model_selection import cross_validate

scores = cross_validate(dt, train_input, train_target)
print(scores)
```

!['img11'](assets/img/ML_week5/img11.png)

이 함수는 fit_time, score_time, test_score 키를 가진 딕셔너리를 반환한다. 
처음 2개의 키는 각각 모델을 훈련하는 시간과 검증하는 시간을 의미한다. 
각 키마다 5개의 숫자가 담겨 있다. 
cross_validate() 함수는 기본적으로 5-폴드 교차 검증을 수행하는데, cv매개변수에서 폴드 수를 바꿀 수도 있다. 

교차 검증의 최종 점수는 test_score 키에 담긴 5개의 점수를 평균하여 얻을 수 있다. 이름은 test_score지만 검증 폴드의 점수임을 혼동하지 말 것!

```python
import numpy as np

print(np.mean(scores['test_score']))
```

교차 검증을 수행하면 입력한 모델에서 얻을 수 있는 최상의 검증 점수를 가능해 볼 수 있다. 

한 가지 주의할 점은 cross_validate()는 훈련 세트를 섞어 폴드를 나누지 않는다. 
만약 교차 검증 시 훈련 세트를 섞으려면 분할기(splitter)를 지정해야 한다. 


사이킷런의 분할기는 교차 검증에서 폴드를 어떻게 나눌지 결정해 준다. 
cross_validate() 함수는 기본적으로 회귀 모델일 경우 KFold 분할기를 사용하고 분류 모델일 경우 타깃 클래스를 골고루 나누기 위해 StratifiedKFold를 사용한다. 

```python
from sklearn.model_selection import StratifiedKFold

scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))
#0.8553..

#10-폴드 교차 검증 수행
splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_validate(dt, train_input, train_target, cv=splitter)
print(np.mean(scores['test_score']))
#0.8574...
```

KFold 클래스도 동일한 방식으로 사용할 수 있다.

이제 결정 트리의 매개변수 값을 바꿔가며 가장 좋은 성능이 나오는 모델을 찾아보자. 


#### 하이퍼파라미터 튜닝 ####

모델이 학습할 수 없어 사용자가 지정해야만 하는 파라미터를 하이퍼파라미터라고 한다. 
사이킷런과 같은 ML 라이브러리를 사용할 때 이런 하이퍼파라미터는 모두 클래스나 메서드의 매개변수로 표현된다. 

- 하이퍼파라미터 튜닝 과정:
1. 라이브러리가 제공하는 기본값을 그대로 사용해 모델을 훈련한다. 
2. 검증 세트의 점수나 교차 검증을 통해 매개변수를 조금씩 바꿔본다. 

> 사람의 개입 없이 하이퍼파라미터 튜닝을 자동으로 수행하는 기술을 'AutoML'이라고 부른다. 

매개변수가 많아지면 최적의 매개변수 조합을 찾는 일이 점점 더 복잡해진다. 
파이썬의 for문으로 직접 구현할 수도 있겠지만 사이킷런에서 제공하는 **그리드 서치**를 사용해보자. 

- GridSearchCV 클래스: 하이퍼파라미터 탐색과 교차 검증을 한 번에 수행한다. 즉, 따로 cross_validate() 함수를 호출할 필요가 없다. 

기본 매개변수를 사용한 DT모델에서 min_impurity_decrease 매개변수의 최적값을 찾아보자. 

```python
from sklearn.model_selection import GridSearchCV

params = {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}

# GridSearchCV클래스에 탐색 대상 모델과 params 변수를 전달하여 그리드 서치 객체를 만든다.
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)

gs.fit(train_input, train_target)
```

GridSearchCV의 cv 매개변수 기본값은 5이므로 min_impurity_decrease 값마다 5-폴드 교차 검증을 수행한다. 결국 5*5=25개의 모델을 훈련한다. 많은 모델을 훈련하기에 GridSearchCV 클래스의 n_jobs 매개변수에서 병렬 실행에 사용할 CPU 코어 수를 지정하는 것이 좋다. 기본값은 1인데, -1로 지정하면 시스템에 있는 모든 코어를 사용한다. 

편리하게도 사이킷런의 그리드 서치는 훈련이 끝나면 25개의 모델 중 검증 점수가 가장 높은 모델의 매개변수 조합으로 전체 훈련 세트에서 자동으로 다시 모델을 훈련한다. 이 모델은 gs객체의 best_estimator_ 속성에 저장되어 있다. 

```python
dt = gs.best_estimator_
print(dt.score(train_input, train_target))
# 0.9615162593804117

# 최적의 매개변수
print(gs.best_params_)
# {'min_impurity_decrease': 0.0001}
```

각 매개변수에서 수행한 교차 검증의 평균 점수는 cv_results_ 속성의 'mean_test_score' 키에 저장되어 있다. 5번의 교차 검증으로 얻은 점수를 출력해보자.

```python
print(gs.cv_results_['mean_test_score'])
#[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]
```

넘파이의 argmax() 함수를 사용하면 가장 큰 값의 인덱스를 추출할 수 있다. 이 인덱스를 사용해 params 키에 저장된 매개변수를 출력할 수 있다. 이 값이 최상의 검증 점수를 만든 매개변수 조합이다. 앞에서 출력한 gs.best_params_와 동일한지 확인해보자.

```python
best_index = np.argmax(gs.cv_results_['mean_test_score'])
print(gs.cv_results_['params'][best_index])
# {'min_impurity_decrease': 0.0001}
```

> 과정 정리
1. 탐색할 매개변수 지정
2. 훈련 세트에서 그리드 서치를 수행하여 최사의 평균 검증 점수가 나오는 매개변수 조합 찾기
3. 그리드 서치는 최상의 매개변수에서 검증 세트를 포함한 훈련 세트를 사용하여 최종 모델 훈련


이번엔 min_impurity_decrease, max_depth, min_samples_split의 최적 조합을 찾아보자

```python
params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),
          'max_depth': range(5, 20, 1),
          'min_samples_split': range(2, 100, 10)
          }
# 이 매개변수로 수행할 교차 검증 횟수는 9*15*10 = 1350개다. 기본 5-폴드 교차 검증을 수행하므로 만들어지는 모델는 6750개다. 

gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)

# 최상의 매개변수 조합 확인
print(gs.best_params_)
# {'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}

#최상의 교차 검증 점수 확인
print(np.max(gs.cv_results_['mean_test_score']))
# 0.8683865773302731
```


**랜덤 서치**

매개변수의 값이 수치일 때 값의 범위나 간격을 미리 정하기 어려울 수 있다.
또 너무 많은 매개변수 조건이 있어 그리드 서치 수행 시간이 오래 걸릴 수 있다. 
이럴 때 **랜덤 서치**를 사용한다. 

랜덤서치에는 매개변수 값의 목록을 전달하는 것이 아니라 매개변수를 샘플링할 수 있는 확률 분포 객체를 전달한다.

> 싸이파이(scipy)는 파이썬의 핵심 과학 라이브러리 중 하나로 적분, 보간, 선형 대수, 확률 등을 포함한 수치 계산 전용 라이브러리다. 사이킷런은 넘파이와 싸이파이 기능을 많이 사용한다.

- uniform, radint 클래스: 주어진 범위에서 고르게 값을 뽑는다. 즉, 균등 분포에서 샘플링한다. randint는 정숫값을 뽑고, uniform은 실숫값을 뽑는다. 

```python
from scipy.stats import uniform, randint

# 0~10 사이의 범위를 갖는 randint 객체를 만들고 10개의 숫자를 샘플링해보자.
rgen = randint(0, 10)
rgen.rvs(10)
# array([4, 7, 6, 8, 9, 3, 8, 3, 1, 4])

# 1000개 샘플링
np.unique(rgen.rvs(1000), return_counts=True)
# (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
#  array([116, 105,  95, 100,  84,  90,  97,  95, 107, 111]))

# uniform 사용하여 10개 실수 추출
ugen = uniform(0, 1)
ugen.rvs(10)
# array([0.07156624, 0.51330724, 0.78244744, 0.14237963, 0.05055468,
#        0.13124955, 0.15801332, 0.99110938, 0.08459786, 0.92447632])
```

이제 매개변수의 딕셔너리를 만들어보자. 

```python
params = {'min_impurity_decrease': uniform(0.0001, 0.001),
          'max_depth': randint(20, 50),
          'min_samples_split': randint(2, 25),
          'min_samples_leaf': randint(1, 25),
          }

# 샘플링 횟수는 RandomizedSearchCV의 n_inter 매개변수에 저장
# 그리드 서치보다 훨씬 교차 검증 수는 줄이면서 넓은 영역을 효과적으로 탐색할 수 있다. 
from sklearn.model_selection import RandomizedSearchCV

gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params,
                        n_iter=100, n_jobs=-1, random_state=42)
gs.fit(train_input, train_target)

# 최적의 매개변수 조합 출력
print(gs.best_params_)
# {'max_depth': 39, 'min_impurity_decrease': 0.00034102546602601173, 'min_samples_leaf': 7, 'min_samples_split': 13}

# 최고의 교차 검증 점수 출력
print(np.max(gs.cv_results_['mean_test_score']))
# 0.8695428296438884

# 최종 모델의 테스트 세트 성능 확인
dt = gs.best_estimator_

print(dt.score(test_input, test_target))
# 0.86
```


### 핵심 패키지와 함수 ###

> scikit-learn
- **cross_validate()**: 교차 검증을 수행하는 함수
- 첫 번째 매개변수에 교차 검증으 수행할 모델 객체 전달, 두 번째와 세 번째 매개변수에 특성과 타깃 전달
- scoring 매개변수에 검증에 사용할 평가 지표를 지정할 수 있다. 기본적으로 분류 모델은 정확도를 의미하는 'accuracy', 회귀 모델은 결정계수를 의미하는 'r2'가 된다.'
- cv 매개변수에 교차 검증 폴드 수나 splitter 객체를 지정할 수 있으며 기본값은 5다. 회귀일 때는 KFold 클래스를 사용하고, 분류일 때는 StratifiedKFold 클래스를 사용하여 5-폴드 교차 검증을 수행한다. 
- **GridSearchCV**: 교차 검증으로 하이퍼파라미터 탐색 수행. 최상의 모델을 찾은 후 훈련 세트 전체를 사용해 최종 모델 훈련까지 수행.
- 첫 번째 매개변수로 그리드 서치를 수행할 모델 객체를 전달한다. 두 번째 매개변수에는 탐색할 모델의 매개변수와 값을 전달한다. 
- scoring, cv, n_jobs, return_train_score 매개변수는 cross_validate() 함수와 동일하다. 
- **RandomizedSearchCV**: 교차 검증으로 랜덤한 하이퍼파라미터 탐색을 수행한다. 최상의 모델을 찾은 후 훈련 세트 전체를 사용해 최종 모델을 훈련한다. 
- 첫 번째 매개변수로 그리드 서치를 수행할 모델 객체를 전달한다. 두 번째 매개변수에는 탐색할 모델의 매개변수와 확률 분포 객체를 전달한다. 
- scoring, cv, n_jobs, return_train_score 매개변수는 cross_validate() 함수와 동일하다. 



## 트리의 앙상블 ##

> **핵심 키워드: 앙상블 학습, 랜덤 포레스트, 엑스트라 트리, 그레이디언트 부스팅**




